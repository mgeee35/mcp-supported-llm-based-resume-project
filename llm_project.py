# -*- coding: utf-8 -*-
"""llm-project.ipynb

Automatically generated by Colab.

"""

!pip install colab-xterm

!curl https://ollama.ai/install.sh | sh

!ollama serve &

!ollama pull llama3.1:8b

!ollama serve & sleep 5 && curl http://127.0.0.1:11434

!ollama serve & sleep 10 && curl http://127.0.0.1:11434 && sleep 10 && ollama pull llama3.1:8b

!ollama serve & sleep 5 && ollama run llama3.1:8b

!ollama serve & sleep 5 && /usr/local/bin/ollama --version

!ollama serve & sleep 5 && /usr/local/bin/ollama list

!pkill ollama
!/usr/local/bin/ollama serve & sleep 5 && curl http://127.0.0.1:11434

!pip install ollama
!pip install langchain langchain-community
!pip install pyyaml
!apt-get update
!apt-get install -y texlive texlive-fonts-extra latexmk

!pkill ollama
!ollama serve & sleep 5 && curl http://127.0.0.1:11434

# Commented out IPython magic to ensure Python compatibility.
# %load_ext colabxterm

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext colabxterm
# %xterm

import ollama
try:
    response = ollama.chat(model='llama3.1:8b', messages=[
        {'role': 'user', 'content': 'ikinci cümle nedir?'}
    ])
    print(response['message']['content'])
except Exception as e:
    print(f"Hata: {e}")

'''
Burada doğrudan Google Drive'a bağlanır.
BİRİNCİ KISIM
'''

import ollama
from google.colab import drive

# Google Drive'ı bağla ve özgeçmiş dosyasını oku
def load_resume(file_path):
    # Google Drive'ı bağla
    drive.mount('/content/drive', force_remount=True)
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        return f"Hata: '{file_path}' dosyası bulunamadı. Lütfen Google Drive'da dosyanın mevcut olduğundan emin olun."

# Ollama ile sorgu gönder
def query_ollama(prompt, model="llama3.1:8b", host="127.0.0.1:11434"):
    try:
        # Ollama istemcisini harici sunucu ile yapılandır
        ollama.Client(host=host)
        response = ollama.chat(
            model=model,
            messages=[{'role': 'user', 'content': prompt}],
            options={'host': host}
        )
        return response['message']['content']
    except Exception as e:
        return f"Hata: Ollama API'sine bağlanılamadı. {e}"

# Ana fonksiyon
def main():
    resume_file = "/content/drive/My Drive/llm-project/resume.txt"  # Google Drive'daki dosya yolu
    resume_content = load_resume(resume_file)

    if "Hata" in resume_content:
        print(resume_content)
        return

    # Konsol üzerinden sorular al
    print("Özgeçmiş projesine hoş geldiniz! Sorularınızı sorabilirsiniz (Çıkmak için 'exit' yazın).")
    while True:
        question = input("Soru: ")
        if question.lower() == "exit":
            print("Programdan çıkılıyor...")
            break

        # Sorgu için prompt oluştur
        prompt = f"Aşağıdaki özgeçmiş bilgilerine dayanarak soruyu cevapla. Yanıtı kısa ve öz tut:\n\n{resume_content}\n\nSoru: {question}"

        # Ollama'dan yanıt al
        response = query_ollama(prompt, host="127.0.0.1:11434")
        print(f"Cevap: {response}\n")

if __name__ == "__main__":
    main()

'''
Burada doğrudan Google Drive'a bağlanmadan Choose Files butonu ile
dosyalar import edilir.
BİRİNCİ KISIM
'''

import ollama
from google.colab import files

# Özgeçmiş dosyasını yükle ve oku
def load_resume():
    print("Lütfen resume.txt dosyasını yükleyin.")
    uploaded = files.upload()
    file_name = list(uploaded.keys())[0]  # İlk yüklenen dosyanın adını al
    try:
        resume_content = uploaded[file_name].decode('utf-8')  # Dosya içeriğini oku
        return resume_content
    except Exception as e:
        return f"Hata: Dosya okunamadı. {e}"

# Ollama ile sorgu gönder
def query_ollama(prompt, model="llama3.1:8b", host="127.0.0.1:11434"):
    try:
        # Ollama istemcisini harici sunucu ile yapılandır
        ollama.Client(host=host)
        response = ollama.chat(
            model=model,
            messages=[{'role': 'user', 'content': prompt}],
            options={'host': host}
        )
        return response['message']['content']
    except Exception as e:
        return f"Hata: Ollama API'sine bağlanılamadı. {e}"

# Ana fonksiyon
def main():
    # Özgeçmiş dosyasını yükle
    resume_content = load_resume()

    if "Hata" in resume_content:
        print(resume_content)
        return

    # Konsol üzerinden sorular al
    print("Özgeçmiş projesine hoş geldiniz! Sorularınızı sorabilirsiniz (Çıkmak için 'exit' yazın).")
    while True:
        question = input("Soru: ")
        if question.lower() == "exit":
            print("Programdan çıkılıyor...")
            break

        # Sorgu için prompt oluştur
        prompt = f"Aşağıdaki özgeçmiş bilgilerine dayanarak soruyu cevapla. Yanıtı kısa ve öz tut:\n\n{resume_content}\n\nSoru: {question}"

        # Ollama'dan yanıt al
        response = query_ollama(prompt, host="127.0.0.1:11434")
        print(f"Cevap: {response}\n")

if __name__ == "__main__":
    main()

'''
PDF oluşturma
İKİNCİ KISIM
'''

import ollama
from google.colab import files
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
import re
import os

# Özgeçmiş dosyasını yükle ve oku
def load_resume():
    print("Lütfen resume.txt dosyasını yükleyin.")
    uploaded = files.upload()
    file_name = list(uploaded.keys())[0]  # İlk yüklenen dosyanın adını al
    try:
        resume_content = uploaded[file_name].decode('utf-8')  # Dosya içeriğini oku
        with open(file_name, 'w', encoding='utf-8') as f:
            f.write(resume_content)  # Dosyayı Colab ortamına kaydet
        return resume_content, file_name
    except Exception as e:
        return f"Hata: Dosya okunamadı. {e}", None

# LaTeX ile PDF oluştur
def generate_pdf(resume_content, output_file="resume.pdf"):
    # LaTeX içeriği oluştur
    latex_content = r"""
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{parskip}
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\begin{document}

\section*{Özgeçmiş}
""" + "\n".join([f"\\noindent {line}" for line in resume_content.splitlines()]) + r"""
\end{document}
"""
    # LaTeX dosyasını kaydet
    with open("resume.tex", "w", encoding="utf-8") as f:
        f.write(latex_content)

    # LaTeX'i PDF'e dönüştür
    try:
        os.system("latexmk -pdf resume.tex")
        if os.path.exists("resume.pdf"):
            os.rename("resume.pdf", output_file)
            print(f"PDF oluşturuldu: {output_file}")
            files.download(output_file)
            return True
        else:
            return f"Hata: PDF oluşturulamadı."
    except Exception as e:
        return f"Hata: PDF oluşturulamadı. {e}"

# Ana fonksiyon
def main():
    # Özgeçmiş dosyasını yükle
    resume_content, resume_file = load_resume()

    if "Hata" in resume_content:
        print(resume_content)
        return

    # LangChain ile Ollama modelini yapılandır
    llm = Ollama(model="llama3.1:8b", base_url="http://127.0.0.1:11434")

    # Prompt şablonu oluştur
    prompt_template = PromptTemplate(
        input_variables=["resume", "question"],
        template="Aşağıdaki özgeçmiş bilgilerine dayanarak soruyu cevapla. Yanıtı kısa ve öz tut:\n\n{resume}\n\nSoru: {question}"
    )

    # Konsol üzerinden sorular al
    print("Özgeçmiş projesine hoş geldiniz! Sorularınızı sorabilirsiniz (Çıkmak için 'exit' yazın).")
    while True:
        question = input("Soru: ")
        if question.lower() == "exit":
            print("Programdan çıkılıyor...")
            break

        # PDF oluşturma komutunu kontrol et
        if re.search(r"pdf.*oluştur", question.lower()):
            # Özgeçmiş sahibinin adını çıkar (örneğin, "Ahmet Yılmaz’ın özgeçmişinin PDF’ini oluştur.")
            match = re.search(r"(\w+\s+\w+)", question)
            if match:
                person_name = match.group(1)
                output_file = f"{person_name.replace(' ', '_')}_resume.pdf"
                result = generate_pdf(resume_content, output_file)
                print(result)
            else:
                print("Hata: PDF oluşturmak için özgeçmiş sahibinin adı belirtilmeli (örneğin, 'Ahmet Yılmaz’ın özgeçmişinin PDF’ini oluştur.').")
            continue

        # Sorgu için prompt oluştur
        prompt = prompt_template.format(resume=resume_content, question=question)

        # Ollama'dan yanıt al
        try:
            response = llm.invoke(prompt)
            print(f"Cevap: {response}\n")
        except Exception as e:
            print(f"Hata: Ollama API'sine bağlanılamadı. {e}\n")

if __name__ == "__main__":
    main()

'''
MCP dosyası oluşturulur.
ÜÇÜNCÜ KISIM
'''

import ollama
from google.colab import files
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
import re
import os
import yaml

# Özgeçmiş dosyasını yükle ve oku
def load_resume():
    print("Lütfen resume.txt dosyasını yükleyin.")
    uploaded = files.upload()
    file_name = list(uploaded.keys())[0]  # İlk yüklenen dosyanın adını al
    try:
        resume_content = uploaded[file_name].decode('utf-8')  # Dosya içeriğini oku
        with open(file_name, 'w', encoding='utf-8') as f:
            f.write(resume_content)  # Dosyayı Colab ortamına kaydet
        return resume_content, file_name
    except Exception as e:
        return f"Hata: Dosya okunamadı. {e}", None

# MCP yapılandırma dosyası oluştur
def generate_mcp_config(resume_content, output_file="mcp_config.yaml"):
    mcp_config = {
        "version": "1.0",
        "context": {
            "type": "text",
            "source": {
                "content": resume_content
            }
        },
        "metadata": {
            "description": "Özgeçmiş içeriği",
            "created_at": "2025-06-25",
            "language": "tr"
        }
    }
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(mcp_config, f, allow_unicode=True, sort_keys=False)
        print(f"MCP yapılandırma dosyası oluşturuldu: {output_file}")
        files.download(output_file)
        return True
    except Exception as e:
        return f"Hata: MCP dosyası oluşturulamadı. {e}"

# LaTeX ile PDF oluştur (satır satır format)
def generate_pdf(resume_content, output_file="resume.pdf"):
    # LaTeX içeriği oluştur, satır satır formatı koru
    latex_content = r"""
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{parskip}
\usepackage{enumitem}
\setlist{leftmargin=*}
\begin{document}

\begin{center}
{\Large \textbf{Özgeçmiş}}
\end{center}
\vspace{10pt}

"""
    # Özgeçmiş içeriğini satır satır işle
    lines = resume_content.splitlines()
    current_section = None
    for line in lines:
        line = line.strip()
        if not line:
            latex_content += r"\vspace{10pt}" + "\n"
            continue
        if line in ["Eğitim:", "İş Deneyimi:", "Beceriler:"]:
            if current_section:
                latex_content += r"\end{itemize}" + "\n"
            current_section = line
            latex_content += r"\noindent \textbf{" + line[:-1] + r"} \\ \vspace{5pt}" + "\n"
            latex_content += r"\begin{itemize}" + "\n"
        elif line.startswith("- ") or line.startswith("  * "):
            latex_content += r"\item " + line.lstrip("- * ") + r" \\ " + "\n"
        else:
            if current_section:
                latex_content += r"\end{itemize}" + "\n"
                current_section = None
            latex_content += r"\noindent " + line + r" \\ " + "\n"

    if current_section:
        latex_content += r"\end{itemize}"
    latex_content += r"\end{document}"

    # LaTeX dosyasını kaydet
    with open("resume.tex", "w", encoding="utf-8") as f:
        f.write(latex_content)

    # LaTeX'i PDF'e dönüştür
    try:
        os.system("latexmk -pdf resume.tex")
        if os.path.exists("resume.pdf"):
            os.rename("resume.pdf", output_file)
            print(f"PDF oluşturuldu: {output_file}")
            files.download(output_file)
            return True
        else:
            return f"Hata: PDF oluşturulamadı."
    except Exception as e:
        return f"Hata: PDF oluşturulamadı. {e}"

# Ana fonksiyon
def main():
    # Özgeçmiş dosyasını yükle
    resume_content, resume_file = load_resume()

    if "Hata" in resume_content:
        print(resume_content)
        return

    # MCP yapılandırma dosyasını oluştur
    mcp_result = generate_mcp_config(resume_content)
    if isinstance(mcp_result, str) and "Hata" in mcp_result:
        print(mcp_result)

    # LangChain ile Ollama modelini yapılandır
    llm = Ollama(model="llama3.1:8b", base_url="http://127.0.0.1:11434")

    # Prompt şablonu oluştur
    prompt_template = PromptTemplate(
        input_variables=["resume", "question"],
        template="Aşağıdaki özgeçmiş bilgilerine dayanarak soruyu cevapla. Yanıtı kısa ve öz tut:\n\n{resume}\n\nSoru: {question}"
    )

    # Konsol üzerinden sorular al
    print("Özgeçmiş projesine hoş geldiniz! Sorularınızı sorabilirsiniz (Çıkmak için 'exit' yazın).")
    print("Not: Soru-cevap için Ollama sunucusu, PDF oluşturma için gerek yoktur. MCP dosyası Claude ile kullanılabilir.")
    while True:
        question = input("Soru: ")
        if question.lower() == "exit":
            print("Programdan çıkılıyor...")
            break

        # PDF oluşturma komutunu kontrol et
        if re.search(r"pdf.*oluştur", question.lower()):
            # Özgeçmiş sahibinin adını çıkar
            match = re.search(r"(\w+\s+\w+)", question)
            if match:
                person_name = match.group(1)
                output_file = f"{person_name.replace(' ', '_')}_resume.pdf"
            else:
                output_file = "resume.pdf"
            result = generate_pdf(resume_content, output_file)
            print(result if isinstance(result, str) else f"PDF başarıyla oluşturuldu ve indirildi: {output_file}")
            continue

        # Sorgu için prompt oluştur
        prompt = prompt_template.format(resume=resume_content, question=question)

        # Ollama'dan yanıt al
        try:
            response = llm.invoke(prompt)
            print(f"Cevap (Ollama): {response}\n")
        except Exception as e:
            print(f"Hata: Ollama API'sine bağlanılamadı. {e}\n")
            print("Lütfen http://127.0.0.1:11434 yerine geçerli bir Ollama sunucu URL'si sağlayın.")
            print("Alternatif: MCP dosyasını (mcp_config.yaml) Claude'ye yükleyerek soruları Claude üzerinden sorabilirsiniz.")

if __name__ == "__main__":
    main()
